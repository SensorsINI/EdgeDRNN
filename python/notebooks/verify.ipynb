{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   468 -10080  -2800  -2236    605  -6480   -720   2100  -1890    192\n",
      "    440   6708   7018   2592    144   -336]\n",
      "[-4019]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "rnn_gold = np.asarray([-18,-210,-112,-52,-11,-180,-80,100,-210,-8,-20,156,121,144,8,-8])\n",
    "cl_weight = np.asarray([-26,48,25,43,-55,36,9,21,9,-24,-22,43,58,18,18,42])\n",
    "cl_bias = np.asarray([1])\n",
    "mult = rnn_gold * cl_weight\n",
    "\n",
    "cl_out = np.sum(mult) + cl_bias*256\n",
    "print(mult)\n",
    "print(cl_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.autograd.function import Function\n",
    "class GradPreserveRound(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        output = torch.round(input)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_input = grad_output\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = grad_output\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "class GradPreserveFloor(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        output = torch.floor(input)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_input = grad_output\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = grad_output\n",
    "        return grad_input\n",
    "def quantize_tensor(x: Tensor, qi: int, qf: int, enable: int = 0, use_floor: bool = False) -> Tensor:\n",
    "    \"\"\"\n",
    "    :param x: input tensor\n",
    "    :param qi: number of integer bits before the decimal point\n",
    "    :param qf: number of fraction bits after the decimal point\n",
    "    :param enable: if 0, return x\n",
    "    :param use_floor: Whether use floor() instead of round()\n",
    "    :return: tensor quantized to fixed-point precision\n",
    "    \"\"\"\n",
    "    if enable == 0:\n",
    "        return x\n",
    "    else:\n",
    "        power = torch.tensor(float(2. ** qf), dtype=torch.float32)\n",
    "        clip_val = torch.tensor(float(2. ** (qi + qf - 1) - 1), dtype=torch.float32)\n",
    "        if use_floor:\n",
    "            value = GradPreserveFloor.apply(x * power)\n",
    "        else:\n",
    "            value = GradPreserveRound.apply(x * power)  # Round Half to Even\n",
    "\n",
    "        value = torch.max(value, -clip_val)\n",
    "        value = torch.min(value, clip_val)\n",
    "        # value = torch.clamp(value, -clip_val, clip_val - 1)  # saturation arithmetic\n",
    "        value = torch.div(value, power)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0078125000)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=10)\n",
    "a = torch.tensor(1.0)\n",
    "b = quantize_tensor(1, 8, 8, enable=1, use_floor=False)\n",
    "value = torch.div(a, 128.0)\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0078125\n"
     ]
    }
   ],
   "source": [
    "a = 1\n",
    "b = 128\n",
    "c = a/b\n",
    "print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
